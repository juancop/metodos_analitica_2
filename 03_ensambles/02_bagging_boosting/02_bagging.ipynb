{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de Bagging\n",
        "\n",
        "En este Notebook llevaremos acabo un ejemplo de implementación de Bagging, para facilitar el entendimiento del funcionamiento de los modelos. \n",
        "\n",
        "Se utilizará como modelo base el `DecisionTreeRegressor` de Sci-Kit Learn para el problema de Predicción de Precios de Viviendas en Boston. \n",
        "\n",
        "En este notebook usted irá implementando paso a paso los elementos que componen el algoritmo. \n",
        "\n",
        "\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
        "\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/juancop/metodos_analitica_2/blob/main/03_ensambles/02_bagging_boosting/02_bagging.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/juancop/metodos_analitica_2/blob/03_ensambles/02_bagging_boosting/02_bagging.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /></a>\n",
        "  </td>\n",
        "  \n",
        "</table>"
      ],
      "metadata": {
        "id": "O4Vd6ClX_2Yn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_nGmbQ4314x"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import load_boston\n",
        "from joblib import Parallel, delayed\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de Datos\n",
        "\n",
        "Utilizaremos los Datasets de Sci-Kit Learn para cargar la información de precios de vivienda."
      ],
      "metadata": {
        "id": "39gqXpvJA4Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston_housing = load_boston()"
      ],
      "metadata": {
        "id": "7jibq5Gm352H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_housing.keys() # Elementos con los que vienen los datos"
      ],
      "metadata": {
        "id": "ZsxBlg4836iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos datos vienen como arrays de NumPy y sin nombres de campos. A cotninuación los convertiremos en DataFrames y asignaremos los nombres a nuestras variables explicativas."
      ],
      "metadata": {
        "id": "qmuejFx1CY7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(boston_housing['data'], columns = boston_housing['feature_names'])\n",
        "y = pd.DataFrame(boston_housing['target'])"
      ],
      "metadata": {
        "id": "BZ4cGy_t37AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "C3fOdEMUsHVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "omR21sIqs9Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Procesamiento de Datos\n",
        "\n",
        "A continuación dividiremos la información en Train y Test, y realizaremos un escalamiento de datos.\n",
        "\n",
        "Para la división en train-test, utilice la función de [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ],
      "metadata": {
        "id": "uvSQgabjCsJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Utilice train_test_split para dividir los datos en entrenamiento y test.\n",
        "X_train, X_test, y_train, y_test = None # Utilice como random_state = 42\n",
        "###"
      ],
      "metadata": {
        "id": "wiHgpKz1quru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "VdtghgistAn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se sugiere realizar un MinMax scaler como procesamiento inicial de las features. Usted puede probar con otros procesamientos. \n",
        "\n",
        "Para esto, utilice [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). "
      ],
      "metadata": {
        "id": "TV8BPBuLEOyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "\n",
        "scaler = None\n",
        "X_train.values[:] = scaler.transform(X_train)\n",
        "X_test.values[:] = scaler.transform(X_test)\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "kBQ_f8DNJ2Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el procesamiento anterior, es posible comenzar a programar los modelos que vamos a utilizar."
      ],
      "metadata": {
        "id": "0hAoiauhEfGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de Bagging\n",
        "\n",
        "Recordemos que Bagging consiste de tres elementos: \n",
        "- Muestreo aleatorio con reemplazamiento de los datos de entrenamiento (muestras bootstrap)\n",
        "\n",
        "- Entrenamiento del mismo modelo en cada una de las diferentes $B$ muestras, \n",
        "$$\\Big\\{\\hat{f}_b(x) \\Big\\}_{b = 1, \\dots, B}$$\n",
        "\n",
        "- Combinación de predicciones a través de un promedio simple, \n",
        "\n",
        "$$\\hat{f}_{bagging} (x) = \\frac{1}{B} \\sum_{b = 1}^B \\hat{f}_b(x)$$\n",
        "\n",
        "Vamos a crear una clase que nos permita estimar un conjunto de árboles de regresión ($\\hat{f}_b(x)$) y lo utilizaremos para predecir. "
      ],
      "metadata": {
        "id": "a_U4wgYAv7J_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Boostrap Sampling\n",
        "\n",
        "El primer elemento de la función es quizás el más importante del *Bagging*, pues corresponde al muestreo aleatorio con reemplazamiento. \n",
        "\n",
        "\n",
        "Utilice el métoo de [`pd.DataFrame.sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) para tomar una muestra aleatoria con reemplazamiento **de las filas**."
      ],
      "metadata": {
        "id": "Yv-iIpWaHXnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _sample_features(self, X, y, random_state = None):\n",
        "  \"\"\"\n",
        "  Generación de [una] muestra Bootstrap para entrenar un modelo de árbol de regresión.\n",
        "\n",
        "  Params\n",
        "  --------\n",
        "    X (pandas.DataFrame):\n",
        "      Un dataframe que contiene los features de entrenamiento\n",
        "\n",
        "    y (pandas.DataFrame):\n",
        "      Un dataframe que contiene el target para el entrenamiento\n",
        "\n",
        "    random_state (int):\n",
        "      [Default None] Valor de semilla. Utilizar únicamente para pruebas.\n",
        "\n",
        "\n",
        "  Returns\n",
        "  --------\n",
        "    sampled_x (pandas.DataFrame):\n",
        "      Un dataframe que contiene una muestra bootstrap de los datos originales\n",
        "\n",
        "    sampled_y (pandas.DataFrame):\n",
        "      Un dataframe que contiene una la variable dependiente de cada observación.\n",
        "  \"\"\"\n",
        "  ###\n",
        "\n",
        "  sampled_x = None # Añada dentro del sample, el random state definido como input\n",
        "  sampled_y = None # Asigne a cada X su Y.\n",
        "\n",
        "  ###\n",
        "\n",
        "  return sampled_x, sampled_y"
      ],
      "metadata": {
        "id": "S8PiRP1fH6UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si la función fue programada correctamente, entonces el resultado de la siguiente celda debería ser:\n",
        "\n",
        "|         |         0 |\n",
        "|:--------|----------:|\n",
        "| CRIM    | -22.3237  |\n",
        "| ZN      |  -3.87571 |\n",
        "| INDUS   |  -6.34016 |\n",
        "| CHAS    |  -3.83336 |\n",
        "| NOX     | -35.7036  |\n",
        "| RM      | -21.231   |\n",
        "| AGE     | -46.6513  |\n",
        "| DIS     |  22.7396  |\n",
        "| RAD     | -21.3265  |\n",
        "| TAX     | -32.3898  |\n",
        "| PTRATIO |  37.1405  |\n",
        "| B       | -10.3039  |\n",
        "| LSTAT   |  10.5585  |"
      ],
      "metadata": {
        "id": "pNhxzhjjI68_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sampled_fn, y_sampled_fn = _sample_features(None, X_train, y_train, random_state = 42)\n",
        "X_sampled_fn.sum()"
      ],
      "metadata": {
        "id": "eJMth0q8I56U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de un Árbol\n",
        "\n",
        "La idea de Bagging es entrenar el mismo modelo en diferentes muestras de la base de entrenamiento original. Por esto, deberemos crear una función que genere la muestra *Bootstrap* y entrene el árbol de regresión en esta. \n",
        "\n",
        "Utilice [`sklearn.tree.DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.predict) para su estimador base (su weak learner).\n"
      ],
      "metadata": {
        "id": "UXtmwGSCMlqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_tree(self, X, y):\n",
        "  \"\"\"\n",
        "  Entrena un árbol de regresión en una muestra bootstrap de los datos originales.\n",
        "\n",
        "   Params\n",
        "  --------\n",
        "    X (pandas.DataFrame):\n",
        "      Un dataframe que contiene los features de entrenamiento\n",
        "\n",
        "    y (pandas.DataFrame):\n",
        "      Un dataframe que contiene el target para el entrenamiento\n",
        "\n",
        "  Returns\n",
        "  --------\n",
        "    tree (sklearn.tree.DecisionTreeRegressor):\n",
        "      Un modelo de árbol de regresión ajustado en una muestra \n",
        "      bootstrap de los datos de entrenamiento.\n",
        "\n",
        "  \"\"\"\n",
        "  ###\n",
        "\n",
        "  # 1. Utilice la función _sample_features para generar una muestra\n",
        "  sampled_X, sampled_y = None\n",
        "\n",
        "  # 2. Entrene el modelo de regresión. Fije el parámetro max_features = self.col_prop\n",
        "  tree = None\n",
        "\n",
        "  # 3. Utilice el método .fit() para ajustar el modelo\n",
        "  None\n",
        "\n",
        "  ###\n",
        "  return tree"
      ],
      "metadata": {
        "id": "BBYtKmCwMk73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Todo Junto\n",
        "\n",
        "En la siguiente celda se tiene el código que nos permitirá entrenar en paralelo un número arbitrario de árboles. Esta clase utilizará las funciones definidas anteriormente. \n",
        "\n",
        "La función que se paraleliza es `train_single_tree` y la función de predicción `predict_multiple`."
      ],
      "metadata": {
        "id": "rskCAhsVNy7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaggingRegressor:\n",
        "\n",
        "  def __init__(self, n_trees = 200, col_prop = 0.6, n_jobs = 3):\n",
        "    self.n_trees = n_trees\n",
        "    self.col_prop = col_prop\n",
        "  \n",
        "    self.n_jobs = n_jobs\n",
        "\n",
        "    self.model_list = None\n",
        "    self.X = None\n",
        "    self.y = None\n",
        "\n",
        "\n",
        "  def parallel_fit_training(self, X, y):\n",
        "    \"\"\"\n",
        "    Realiza un entrenamiento en paralelo de la cantidad de árboles especiicados en self.n_trees\n",
        "    \"\"\"\n",
        "    self.model_list = Parallel(n_jobs=self.n_jobs, \n",
        "                               timeout=99999)(delayed(self.train_single_tree)(X, y) for _ in tqdm(range(self.n_trees)))\n",
        "\n",
        "\n",
        "  def predict_multiple(self, X):\n",
        "    \"\"\"\n",
        "    Realiza la predicción de cada elemento del ensamble. \n",
        "\n",
        "    Params\n",
        "    -------\n",
        "      X (pd.DataFrame):\n",
        "        DataFrame que cotiene los features para predecir\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "      prediction_array (numpy.array):\n",
        "        Un array que contiene todas las predicciones de cada \n",
        "        elemento del ensamble.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    prediction_list = Parallel(n_jobs=self.n_jobs, timeout=99999)(delayed(model.predict)((X[model.feature_names_in_])) for model in tqdm(self.model_list))\n",
        "    prediction_array = np.array(prediction_list)\n",
        "    return prediction_array\n",
        "\n",
        "  def predict(self, X, reduce = True):\n",
        "    \"\"\"\n",
        "    Método para realizar las predicciones. \n",
        "\n",
        "    Params\n",
        "    --------\n",
        "      X (pd.DataFrame):\n",
        "        DataFrame que cotiene los features para predecir\n",
        "      \n",
        "      reduce (bool):\n",
        "        [Default True] Indica si se desea que la predicción sea el promedio del \n",
        "        ensamble. Si reduce = False, entonces se devuelve la predicción\n",
        "        de cada modelo individual.\n",
        "    \"\"\"\n",
        "    prediction = self.predict_multiple(X)\n",
        "\n",
        "    if reduce:\n",
        "      return prediction.mean(axis = 0)\n",
        "    else:\n",
        "      return prediction.T\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"\n",
        "    Ajusta el modelo.\n",
        "\n",
        "    Params\n",
        "    --------\n",
        "      X (pd.DataFrame):\n",
        "        Datos de entrenamiento (features)\n",
        "      y (pd.DataFrame):\n",
        "        Target para los datos de entrenamiento\n",
        "\n",
        "    \"\"\"\n",
        "    self.parallel_fit_training(X, y)"
      ],
      "metadata": {
        "id": "fUTIYg0PwKkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta clase añadimos los métodos que creamos anteriormente."
      ],
      "metadata": {
        "id": "LTebvl9DTJ6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BaggingRegressor._sample_features = _sample_features"
      ],
      "metadata": {
        "id": "UjgjkFU_RdV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BaggingRegressor.train_single_tree = train_single_tree"
      ],
      "metadata": {
        "id": "H-Rex8Lzvxre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging Default & Random Forest\n",
        "\n",
        "Como se habló en clase, el Random Forest es un modelo de Bagging, que busca disminuir la correlación entre los modelos al restringir las features a las que tiene acceso cada split. De esta forma, los árboles entrenados son diferentes unos de otros. \n",
        "\n",
        "Si en nuestro `BaggingRegressor` especificamos un `col_prop = 1`, estaremos entrenado un modelo Bagging estándar (default). Si `col_prop < 1`, se estará entrenando un `Random Forest`. \n",
        "\n",
        "A continuación, entrene un modelo Bagging con `col_prop = 1` y otro con `col_prop < 1`. Ambos modelos deben tener `n_trees = 1000`. "
      ],
      "metadata": {
        "id": "xqsBsDmkTO95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Entrenamiento de BaggingEnsemble\n",
        "\n",
        "# Instancie la clase \n",
        "BaggingEnsemble = None\n",
        "\n",
        "# Ajuste el modelo\n",
        "None\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "sXIqJBIkUDDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Entrenamiento de Random Forest\n",
        "\n",
        "# Instancie la clase\n",
        "RandomForest = None # el col prop es un hiperparámetro que toca tunear\n",
        "\n",
        "# Ajuste el modelo\n",
        "None\n",
        "\n",
        "###\n"
      ],
      "metadata": {
        "id": "vOVJ3PPHkCjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desempeño del Modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "24qsUPSzUwQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evolución del Modelo\n",
        "\n",
        "Anteriormente observamos cómo el `RandomForest` tuvo un mejor desempeño que el `BaggingEnsemble`. \n",
        "\n",
        "En esta sección revisaremos cómo evolucionan las métricas de desempeño del modelo a medida que se incluyen más `weak_learners` y si tienen algo que ver con la diferencia de los resultados de evaluación.\n",
        "\n",
        "\n",
        "Realizaremos las predicciones nuevamente, pero esta vez se fijará el parámetro `reduce = False`. De esta forma, no obtendremos una predicción final, sino las predicciones que hicieron cada uno de los 1000 árboles. "
      ],
      "metadata": {
        "id": "toIXNuEFUSjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Predicciones de Bagging Ensemble\n",
        "\n",
        "y_pred_test_bag =  None\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "sNLYN1qDUewt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Predicciones en Random Forest\n",
        "\n",
        "y_pred_test_rf =  None\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "r9-357gpkMlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos las predicciones, queremos ver cómo nos hubiera dado el error del modelo si únicamente hubieramos utilizado los primeros `m` árboles. \n",
        "\n",
        "Para calcular el error del modelo, utilice la función de [`sklearn.metrics.mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
      ],
      "metadata": {
        "id": "ZLaZa2kQViJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_first_m_models(y_true, predictions, m):\n",
        "  \"\"\"\n",
        "  Calcula el MSE de cada modelo utilizando únicamente las primeras m predicciones.\n",
        "  \"\"\"\n",
        "\n",
        "  ### \n",
        "  # 1. Seleccione las primeras m predicciones y calcule el promedio\n",
        "  mth_avg_pred = None\n",
        "\n",
        "  # 2. Calcule el MSE -> use la función mean_squared_error\n",
        "  mse = None\n",
        "\n",
        "  ###\n",
        "  return mse"
      ],
      "metadata": {
        "id": "syd_BJPTokFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_trees = np.arange(1, 1000)"
      ],
      "metadata": {
        "id": "FtllKCf_okHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list_rf = [mse_first_m_models(y_test, y_pred_test_rf, m) for m in n_trees]\n",
        "mse_list_bag = [mse_first_m_models(y_test, y_pred_test_bag, m) for m in n_trees]"
      ],
      "metadata": {
        "id": "w2tn2z7lpofb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSW0V6czqie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 5))\n",
        "plt.plot(n_trees, mse_list_rf, label = 'Bagging (RF) MSE')\n",
        "plt.plot(n_trees, mse_list_bag, label = 'Bagging MSE')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs Número de Árboles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2CzmsLRDpkks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 5))\n",
        "plt.plot(n_trees, mse_list_rf, label = 'Bagging (RF) MSE')\n",
        "plt.plot(n_trees, mse_list_bag, label = 'Bagging MSE')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs Número de Árboles')\n",
        "plt.xlim(0, 100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gIQO8bsvvc6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxIEZSi3dZhc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}